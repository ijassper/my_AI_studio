import google.generativeai as genai
import streamlit as st

# --- í˜ì´ì§€ ì„¤ì • ---
st.set_page_config(
    page_title="ë‚˜ë§Œì˜ Gemini AI",
    page_icon="âœ¨"
)

# --- ì‚¬ì´ë“œë°” ---
with st.sidebar:
    st.title("âœ¨ ë‚˜ë§Œì˜ Gemini")
    st.header("ì„¤ì •")

    try:
        api_key = st.secrets["GOOGLE_API_KEY"]
        genai.configure(api_key=api_key)
    except (KeyError, Exception) as e:
        st.error(f"API í‚¤ ì„¤ì • ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        api_key = st.text_input("Google AI Studio API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”.", type="password")
        if api_key:
            genai.configure(api_key=api_key)
        else:
            st.info("ì‚¬ì´ë“œë°”ì—ì„œ API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            st.stop()
    
    model_options = ("gemini-pro", "gemini-1.5-pro-latest")
    selected_model = st.selectbox(
        "ì‚¬ìš©í•  ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”.",
        model_options,
        index=0
    )

    if st.button("ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”"):
        st.session_state.clear() # ëª¨ë“  ì„¸ì…˜ ìƒíƒœë¥¼ í™•ì‹¤í•˜ê²Œ ì´ˆê¸°í™”
        st.rerun()

# --- ë©”ì¸ í™”ë©´ ---
st.title("Gemini-like Clone")
st.caption(f"í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ ëª¨ë¸: {selected_model}")

# --- ğŸ ë””ë²„ê¹… ì •ë³´ ì¶œë ¥ ì„¹ì…˜ ğŸ ---
# ì´ ì •ë³´ê°€ ë¬¸ì œ í•´ê²°ì˜ í•µì‹¬ì…ë‹ˆë‹¤.
with st.expander("ğŸ ë””ë²„ê¹… ì •ë³´ ë³´ê¸°"):
    st.json(st.session_state.to_dict())


# --- âœ¨ ê¶ê·¹ì˜ ë°©ì–´ ë¡œì§ âœ¨ ---
# í˜„ì¬ ì±„íŒ… ì„¸ì…˜ì´ ìœ íš¨í•œì§€ í™•ì¸í•˜ëŠ” ë³€ìˆ˜
chat_is_valid = False

# st.session_state.chatì´ ì¡´ì¬í•˜ê³ , Noneì´ ì•„ë‹ˆë©°, model_name ì†ì„±ì„ ê°€ì§€ê³  ìˆëŠ”ì§€ ë¨¼ì € í™•ì¸
if "chat" in st.session_state and st.session_state.chat is not None and hasattr(st.session_state.chat, 'model_name'):
    # ëª¨ë“  ì¡°ê±´ì„ í†µê³¼í–ˆìœ¼ë©´, ëª¨ë¸ ì´ë¦„ì´ ì¼ì¹˜í•˜ëŠ”ì§€ ë§ˆì§€ë§‰ìœ¼ë¡œ í™•ì¸
    if st.session_state.chat.model_name.endswith(selected_model):
        chat_is_valid = True

# ì±„íŒ… ì„¸ì…˜ì´ ìœ íš¨í•˜ì§€ ì•Šìœ¼ë©´, ë¬´ì¡°ê±´ ìƒˆë¡œ ë§Œë“­ë‹ˆë‹¤.
if not chat_is_valid:
    # ì´ì „ì— ì±„íŒ… ì„¸ì…˜ì´ ì¡´ì¬í–ˆë‹¤ë©´ 'ëª¨ë¸ ë³€ê²½'ìœ¼ë¡œ ê°„ì£¼
    if "chat" in st.session_state:
        st.info(f"âœ¨ ëª¨ë¸ì„ {selected_model}(ìœ¼)ë¡œ ë³€ê²½í•©ë‹ˆë‹¤. ìƒˆë¡œìš´ ëŒ€í™”ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.")
        st.session_state.messages = [] # ëŒ€í™” ê¸°ë¡ë§Œ ì´ˆê¸°í™”

    try:
        model = genai.GenerativeModel(model_name=selected_model)
        st.session_state.chat = model.start_chat(history=[])
        # ì±„íŒ… ì„¸ì…˜ì„ ì„±ê³µì ìœ¼ë¡œ ìƒì„±í•œ í›„, UIë¥¼ ì •ë¦¬í•˜ê¸° ìœ„í•´ ìƒˆë¡œê³ ì¹¨
        st.rerun()
    except Exception as e:
        st.error(f"ì±„íŒ… ì„¸ì…˜ ìƒì„± ì¤‘ ì‹¬ê°í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
        st.stop()


# ì„¸ì…˜ ìƒíƒœì— ë©”ì‹œì§€ê°€ ì—†ìœ¼ë©´ ì´ˆê¸°í™” (ëª¨ë¸ ë³€ê²½ ì‹œ ìœ„ì—ì„œ ì´ˆê¸°í™”ë  ìˆ˜ ìˆìŒ)
if "messages" not in st.session_state:
    st.session_state.messages = []

# ì´ì „ ëŒ€í™” ë‚´ìš© í‘œì‹œ
for message in st.session_state.messages:
    role = "assistant" if message["role"] == "model" else message["role"]
    with st.chat_message(role):
        st.markdown(message["content"])

# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
if prompt := st.chat_input("ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”!"):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        try:
            response_stream = st.session_state.chat.send_message(prompt, stream=True)
            response = st.write_stream(response_stream)
            st.session_state.messages.append({"role": "model", "content": response})
        except Exception as e:
            st.error(f"âŒ ë©”ì‹œì§€ ì „ì†¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ:\n {e}")
